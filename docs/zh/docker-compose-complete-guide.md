# Docker Compose å®Œæ•´éƒ¨ç½²æŒ‡å—

æœ¬æ–‡æ¡£è®°å½•äº† Ollama + Qwen 72B + Nginx åå‘ä»£ç†çš„å®Œæ•´ Docker Compose éƒ¨ç½²è¿‡ç¨‹ã€‚

## ç›®å½•
1. [æ–¹æ¡ˆæ¦‚è¿°](#æ–¹æ¡ˆæ¦‚è¿°)
2. [é…ç½®æ–‡ä»¶è¯¦è§£](#é…ç½®æ–‡ä»¶è¯¦è§£)
3. [éƒ¨ç½²æ­¥éª¤](#éƒ¨ç½²æ­¥éª¤)
4. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
5. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
6. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## æ–¹æ¡ˆæ¦‚è¿°

### æ¶æ„è®¾è®¡
```
å¤–éƒ¨è®¿é—® â†’ Nginx (80ç«¯å£) â†’ Ollamaå®¹å™¨ (11434ç«¯å£) â†’ GPUæ¨ç†
          â†“
    hostæ¨¡å‹ç›®å½•æŒ‚è½½ (/usr/share/ollama/.ollama)
```

### æ ¸å¿ƒä¼˜åŠ¿
- âœ… **æ¨¡å‹å¤ç”¨**: æŒ‚è½½hostä¸Šå·²æœ‰æ¨¡å‹ï¼Œé¿å…é‡å¤ä¸‹è½½63GBæ•°æ®
- âœ… **æ ‡å‡†ç«¯å£**: é€šè¿‡80ç«¯å£å’ŒåŸŸåè®¿é—® (10.176.202.207.nip.io)
- âœ… **GPUåŠ é€Ÿ**: å®¹å™¨å†…GPUæ”¯æŒï¼Œæ€§èƒ½ä¼˜å¼‚
- âœ… **é«˜å¯ç”¨**: å®¹å™¨è‡ªåŠ¨é‡å¯ï¼ŒæœåŠ¡ç¨³å®š
- âœ… **æ˜“ç®¡ç†**: ç»Ÿä¸€Docker Composeç®¡ç†

---

## é…ç½®æ–‡ä»¶è¯¦è§£

### 1. docker-compose-complete.yml

```yaml
# å®Œæ•´çš„ Ollama + Qwen 72B + Nginx åå‘ä»£ç† Docker Compose é…ç½®
services:
  # Ollama æœåŠ¡ - ä½¿ç”¨å®˜æ–¹é•œåƒï¼Œæ”¯æŒGPUåŠ é€Ÿ
  ollama:
    image: ollama/ollama:latest
    container_name: ollama-service
    ports:
      - "11434:11434"  # Ollama APIç«¯å£ï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_PORT=11434
      # æ€§èƒ½ä¼˜åŒ–é…ç½®
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_FLASH_ATTENTION=1
      - OLLAMA_NUM_PARALLEL=1
    volumes:
      # å…³é”®ï¼šæŒ‚è½½hostä¸Šå·²æœ‰çš„æ¨¡å‹ç›®å½•ï¼ˆé¿å…é‡å¤ä¸‹è½½63GBæ¨¡å‹ï¼‰
      - /usr/share/ollama/.ollama:/root/.ollama
      - ./scripts:/scripts
    restart: unless-stopped
    shm_size: '8gb'  # å¢åŠ å…±äº«å†…å­˜æ”¯æŒå¤§æ¨¡å‹
    # GPUæ”¯æŒé…ç½®
    deploy:
      resources:
        limits:
          memory: 80G  # ä¸º72Bæ¨¡å‹é¢„ç•™å……è¶³å†…å­˜
        reservations:
          memory: 40G
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # ç®€åŒ–å¯åŠ¨å‘½ä»¤ï¼ˆæ¨¡å‹å·²å­˜åœ¨ï¼‰
    entrypoint: ["/bin/bash", "-c"]
    command: |
      "
      echo 'ğŸš€ å¯åŠ¨ Ollama æœåŠ¡ï¼ˆä½¿ç”¨hostä¸Šå·²æœ‰æ¨¡å‹ï¼‰...'
      ollama serve &
      sleep 10
      echo 'ğŸ“‹ æ£€æŸ¥å¯ç”¨æ¨¡å‹...'
      ollama list
      echo 'âœ… æœåŠ¡å°±ç»ªï¼ä½¿ç”¨hostä¸Šçš„æ¨¡å‹æ•°æ® (63GB)'
      wait
      "
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s   # æ¨¡å‹å·²å­˜åœ¨ï¼Œå¿«é€Ÿå¯åŠ¨

  # Nginx åå‘ä»£ç†æœåŠ¡
  nginx:
    image: nginx:alpine
    container_name: nginx-proxy
    ports:
      - "80:80"   # HTTPç«¯å£
      - "443:443" # HTTPSç«¯å£ï¼ˆé¢„ç•™ï¼‰
    volumes:
      - ./nginx/ollama-docker.conf:/etc/nginx/conf.d/default.conf:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      ollama:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

volumes:
  nginx_logs:
    driver: local

networks:
  default:
    name: ollama-network
    driver: bridge
```

### 2. nginx/ollama-docker.conf

å…³é”®é…ç½®ç‚¹ï¼š
- **upstream**: `server ollama:11434` (Dockerå®¹å™¨é—´é€šä¿¡)
- **è¶…æ—¶é…ç½®**: é€‚åº”72Bæ¨¡å‹çš„é•¿æ¨ç†æ—¶é—´
- **æµå¼æ”¯æŒ**: SSEå’ŒWebSocketæ”¯æŒ
- **é”™è¯¯å¤„ç†**: ä¼˜é›…çš„é”™è¯¯é¡µé¢

---

## éƒ¨ç½²æ­¥éª¤

### å‰ç½®æ¡ä»¶æ£€æŸ¥

```bash
# 1. ç¡®è®¤hostä¸Šæ¨¡å‹å­˜åœ¨
sudo du -sh /usr/share/ollama/.ollama/
# é¢„æœŸï¼š63G	/usr/share/ollama/.ollama/

# 2. æ£€æŸ¥GPUæ”¯æŒ
nvidia-smi

# 3. ç¡®è®¤Dockerè¿è¡Œ
sudo docker info
```

### ä¸€é”®éƒ¨ç½²

```bash
# 1. åœæ­¢å¯èƒ½å†²çªçš„hostæœåŠ¡
sudo systemctl stop ollama nginx

# 2. è¿›å…¥é¡¹ç›®ç›®å½•
cd /localhome/admink8s/Development/local-ai-starter

# 3. å¯åŠ¨å®Œæ•´æœåŠ¡æ ˆ
sudo docker compose -f docker-compose-complete.yml up -d

# 4. æ£€æŸ¥æœåŠ¡çŠ¶æ€
sudo docker compose -f docker-compose-complete.yml ps

# 5. æŸ¥çœ‹å¯åŠ¨æ—¥å¿—
sudo docker compose -f docker-compose-complete.yml logs -f
```

### éªŒè¯éƒ¨ç½²

```bash
# ä½¿ç”¨æµ‹è¯•è„šæœ¬
./test-complete.sh

# æˆ–æ‰‹åŠ¨æµ‹è¯•
SERVER_IP=$(hostname -I | awk '{print $1}')
curl http://$SERVER_IP.nip.io/health
curl http://$SERVER_IP.nip.io/api/tags
```

---

## æ€§èƒ½ä¼˜åŒ–

### å…³é”®é…ç½®å‚æ•°

1. **å†…å­˜é…ç½®**
   ```yaml
   shm_size: '8gb'           # å…±äº«å†…å­˜
   memory: 80G               # å†…å­˜é™åˆ¶
   ```

2. **Ollamaç¯å¢ƒå˜é‡**
   ```yaml
   OLLAMA_MAX_LOADED_MODELS=1    # é™åˆ¶åŒæ—¶åŠ è½½æ¨¡å‹æ•°
   OLLAMA_FLASH_ATTENTION=1      # å¯ç”¨Flash Attention
   OLLAMA_NUM_PARALLEL=1         # å¹¶è¡Œæ¨ç†æ•°é‡
   ```

3. **Nginxè¶…æ—¶é…ç½®**
   ```nginx
   proxy_send_timeout 600s;      # 10åˆ†é’Ÿå‘é€è¶…æ—¶
   proxy_read_timeout 600s;      # 10åˆ†é’Ÿè¯»å–è¶…æ—¶
   ```

### æ€§èƒ½é—®é¢˜åˆ†æ

#### æ–‡æœ¬ç”ŸæˆvsèŠå¤©APIæ€§èƒ½å·®å¼‚åŸå› 

ä»æµ‹è¯•ç»“æœçœ‹ï¼š
- **æ–‡æœ¬ç”ŸæˆAPI**: 190ç§’
- **èŠå¤©å¯¹è¯API**: 10ç§’

**å¯èƒ½åŸå› åˆ†æ**ï¼š

1. **æ¨¡å‹å†·å¯åŠ¨**
   - é¦–æ¬¡è°ƒç”¨éœ€è¦åŠ è½½æ¨¡å‹åˆ°GPU
   - 72Bæ¨¡å‹åŠ è½½éœ€è¦å¤§é‡æ—¶é—´
   - åç»­è°ƒç”¨ä¼šåˆ©ç”¨ç¼“å­˜ï¼Œé€Ÿåº¦æ›´å¿«

2. **prompté•¿åº¦å·®å¼‚**
   - ä¸åŒçš„promptå¤æ‚åº¦å½±å“æ¨ç†æ—¶é—´
   - ç”Ÿæˆé•¿åº¦è®¾ç½®ä¸åŒ

3. **å†…å­˜ç®¡ç†**
   - ç¬¬ä¸€æ¬¡æ¨ç†æ—¶è¿›è¡Œå†…å­˜é¢„åˆ†é…
   - GPUæ˜¾å­˜åˆ†é…å’Œä¼˜åŒ–

#### æ€§èƒ½ä¼˜åŒ–å»ºè®®

```bash
# 1. é¢„çƒ­æ¨¡å‹ï¼ˆå‡å°‘å†·å¯åŠ¨æ—¶é—´ï¼‰
curl -X POST http://10.176.202.207.nip.io/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "qwen2.5:72b", "prompt": "Hello", "stream": false}'

# 2. ä½¿ç”¨æµå¼å“åº”ï¼ˆæ›´å¥½çš„ç”¨æˆ·ä½“éªŒï¼‰
curl -X POST http://10.176.202.207.nip.io/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "qwen2.5:72b", "prompt": "Hello", "stream": true}'

# 3. é™åˆ¶ç”Ÿæˆé•¿åº¦
curl -X POST http://10.176.202.207.nip.io/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen2.5:72b", 
    "prompt": "Hello", 
    "options": {"num_predict": 100},
    "stream": false
  }'
```

---

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ç«¯å£å†²çª**
   ```bash
   # æ£€æŸ¥ç«¯å£å ç”¨
   sudo netstat -tlnp | grep :80
   sudo netstat -tlnp | grep :11434
   
   # åœæ­¢å†²çªæœåŠ¡
   sudo systemctl stop ollama nginx
   ```

2. **æ¨¡å‹æŒ‚è½½å¤±è´¥**
   ```bash
   # æ£€æŸ¥æƒé™
   sudo ls -la /usr/share/ollama/.ollama/
   
   # ä¿®å¤æƒé™ï¼ˆå¦‚éœ€è¦ï¼‰
   sudo chown -R 1000:1000 /usr/share/ollama/.ollama/
   ```

3. **GPUä¸å¯ç”¨**
   ```bash
   # æ£€æŸ¥NVIDIA Container Toolkit
   sudo docker run --rm --gpus all nvidia/cuda:12.1-base-ubuntu22.04 nvidia-smi
   ```

4. **Nginxé…ç½®é”™è¯¯**
   ```bash
   # æµ‹è¯•é…ç½®
   sudo docker exec nginx-proxy nginx -t
   
   # é‡å¯nginx
   sudo docker compose -f docker-compose-complete.yml restart nginx
   ```

### æ—¥å¿—æŸ¥çœ‹

```bash
# Ollamaæ—¥å¿—
sudo docker compose -f docker-compose-complete.yml logs ollama

# Nginxæ—¥å¿—
sudo docker compose -f docker-compose-complete.yml logs nginx

# å®æ—¶æ—¥å¿—
sudo docker compose -f docker-compose-complete.yml logs -f
```

---

## æœ€ä½³å®è·µ

### 1. èµ„æºç®¡ç†

```yaml
# ç”Ÿäº§ç¯å¢ƒå»ºè®®é…ç½®
deploy:
  resources:
    limits:
      memory: 64G      # æ ¹æ®å®é™…å†…å­˜è°ƒæ•´
      cpus: '24'       # é™åˆ¶CPUä½¿ç”¨
    reservations:
      memory: 32G
      devices:
        - driver: nvidia
          count: 1       # æŒ‡å®šGPUæ•°é‡
          capabilities: [gpu]
```

### 2. æ•°æ®æŒä¹…åŒ–

```yaml
volumes:
  # æ¨¡å‹æ•°æ®æŒä¹…åŒ–
  - /usr/share/ollama/.ollama:/root/.ollama:ro  # åªè¯»æŒ‚è½½
  
  # æ—¥å¿—æŒä¹…åŒ–
  - ./logs:/var/log/nginx
```

### 3. å®‰å…¨é…ç½®

```nginx
# é™åˆ¶è®¿é—®
location /api/ {
    # IPç™½åå•
    allow 192.168.0.0/16;
    allow 10.0.0.0/8;
    deny all;
    
    # è¯·æ±‚é™åˆ¶
    limit_req zone=api burst=10;
}
```

### 4. ç›‘æ§å’Œå‘Šè­¦

```yaml
# å¥åº·æ£€æŸ¥
healthcheck:
  test: ["CMD", "ollama", "list"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 60s
```

---

## æ€§èƒ½åŸºå‡†

### ç¡¬ä»¶é…ç½®
- **CPU**: 48æ ¸å¿ƒ
- **å†…å­˜**: 251GB
- **GPU**: NVIDIA A100 (ç¤ºä¾‹)
- **å­˜å‚¨**: SSD

### æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | Qwen 32B | Qwen 72B |
|------|----------|----------|
| æ¨¡å‹åŠ è½½æ—¶é—´ | ~30ç§’ | ~60ç§’ |
| é¦–æ¬¡æ¨ç† | ~30ç§’ | ~190ç§’ |
| åç»­æ¨ç† | ~5-15ç§’ | ~10-30ç§’ |
| å†…å­˜ä½¿ç”¨ | ~20GB | ~45GB |
| GPUæ˜¾å­˜ | ~16GB | ~40GB |

### ä¼˜åŒ–å»ºè®®

1. **é¦–æ¬¡è®¿é—®ä¼˜åŒ–**: å®ç°æ¨¡å‹é¢„çƒ­æœºåˆ¶
2. **å¹¶å‘å¤„ç†**: æ ¹æ®ç¡¬ä»¶èµ„æºè°ƒæ•´å¹¶å‘æ•°
3. **ç¼“å­˜ç­–ç•¥**: å®ç°æ™ºèƒ½ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—
4. **è´Ÿè½½å‡è¡¡**: å¤šGPUç¯å¢ƒä¸‹çš„è´Ÿè½½åˆ†é…

---

## éƒ¨ç½²æ¸…å•

- âœ… Docker Composeé…ç½®æ–‡ä»¶
- âœ… Nginxåå‘ä»£ç†é…ç½®  
- âœ… å¯åŠ¨è„šæœ¬ (start-complete.sh)
- âœ… æµ‹è¯•è„šæœ¬ (test-complete.sh)
- âœ… æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—
- âœ… å¥åº·æ£€æŸ¥å’Œé”™è¯¯å¤„ç†
- âœ… æ–‡æ¡£å’Œæœ€ä½³å®è·µ

**æ€»éƒ¨ç½²æ—¶é—´**: 5-10åˆ†é’Ÿï¼ˆæ¨¡å‹å·²å­˜åœ¨ï¼‰
**æ€»å­˜å‚¨éœ€æ±‚**: ~63GBï¼ˆæ¨¡å‹ï¼‰+ ~2GBï¼ˆå®¹å™¨ï¼‰
**è®¿é—®åœ°å€**: http://10.176.202.207.nip.io

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-09-22  
**é€‚ç”¨ç¯å¢ƒ**: RHEL 9.6, Docker Compose v2.39+
