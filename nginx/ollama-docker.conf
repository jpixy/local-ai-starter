# Nginx configuration for Ollama reverse proxy in Docker
# ä¸“ç”¨äºDocker Composeç¯å¢ƒçš„Ollamaåå‘ä»£ç†é…ç½®

# Upstream for Ollama service (Dockerå®¹å™¨é—´é€šä¿¡)
upstream ollama_backend {
    server ollama:11434;  # ä½¿ç”¨Docker ComposeæœåŠ¡å
    keepalive 32;
}

# HTTP server block
server {
    listen 80 default_server;
    server_name 10.176.202.207.nip.io localhost _;

    # æ—¥å¿—é…ç½®
    access_log /var/log/nginx/ollama_access.log;
    error_log /var/log/nginx/ollama_error.log;

    # å®¢æˆ·ç«¯ä¸Šä¼ é™åˆ¶
    client_max_body_size 100M;
    client_body_timeout 120s;
    client_header_timeout 120s;

    # å¥åº·æ£€æŸ¥ç«¯ç‚¹
    location /health {
        return 200 'Nginx proxy is working!\nBackend: Ollama Docker service\nTime: $time_local\n';
        add_header Content-Type text/plain;
        access_log off;
    }

    # æ ¹è·¯å¾„é‡å®šå‘åˆ°APIæ–‡æ¡£
    location = / {
        return 302 /docs;
    }

    # APIæ–‡æ¡£é¡µé¢
    location /docs {
        return 200 '<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ollama API - Dockeréƒ¨ç½²</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif; margin: 40px; background: #f5f7fa; }
        .container { max-width: 900px; margin: 0 auto; background: white; padding: 30px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        .status { background: #e8f5e8; color: #2d5f2d; padding: 15px; border-radius: 5px; margin: 20px 0; border-left: 4px solid #28a745; }
        .endpoint { background: #f8f9fa; padding: 15px; margin: 15px 0; border-radius: 5px; border-left: 4px solid #007acc; }
        .method { color: #007acc; font-weight: bold; font-family: monospace; }
        pre { background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto; font-size: 13px; }
        .warning { background: #fff3cd; color: #856404; padding: 10px; border-radius: 5px; margin: 15px 0; border-left: 4px solid #ffc107; }
        h1 { color: #2c3e50; } h2 { color: #34495e; margin-top: 30px; }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¦™ Ollama API (Docker Compose éƒ¨ç½²)</h1>
        
        <div class="status">
            <strong>âœ… æœåŠ¡çŠ¶æ€:</strong> Dockerå®¹å™¨åŒ–éƒ¨ç½²<br>
            <strong>ğŸŒ è®¿é—®åœ°å€:</strong> 10.176.202.207.nip.io<br>
            <strong>ğŸ³ åç«¯æœåŠ¡:</strong> ollama:11434 (Dockerå†…éƒ¨ç½‘ç»œ)<br>
            <strong>ğŸ“¦ ä»£ç†æœåŠ¡:</strong> nginx:alpine
        </div>

        <h2>ğŸ“‹ API ç«¯ç‚¹</h2>
        
        <div class="endpoint">
            <span class="method">GET</span> /api/tags<br>
            <small>è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨</small>
        </div>
        
        <div class="endpoint">
            <span class="method">POST</span> /api/generate<br>
            <small>ç”Ÿæˆæ–‡æœ¬å“åº” (æ”¯æŒstream: true/false)</small>
        </div>
        
        <div class="endpoint">
            <span class="method">POST</span> /api/chat<br>
            <small>èŠå¤©å¯¹è¯æ¥å£</small>
        </div>

        <div class="endpoint">
            <span class="method">GET</span> /health<br>
            <small>Nginx ä»£ç†å¥åº·æ£€æŸ¥</small>
        </div>
        
        <h2>ğŸ§ª å¿«é€Ÿæµ‹è¯•</h2>

        <h3>1. æ£€æŸ¥å¯ç”¨æ¨¡å‹</h3>
        <pre>curl http://10.176.202.207.nip.io/api/tags</pre>

        <h3>2. æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ (7Bæ¨¡å‹ - å¿«é€Ÿå“åº”)</h3>
        <pre>curl -X POST http://10.176.202.207.nip.io/api/generate -H "Content-Type: application/json" -d "{\"model\": \"qwen2.5:7b\", \"prompt\": \"ä»‹ç»Docker\", \"stream\": false}"</pre>

        <h3>3. èŠå¤©å¯¹è¯ç¤ºä¾‹</h3>
        <pre>curl -X POST http://10.176.202.207.nip.io/api/chat -H "Content-Type: application/json" -d "{\"model\": \"qwen2.5:7b\", \"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½\"}], \"stream\": false}"</pre>

        <div class="warning">
            <strong>âš ï¸ æ³¨æ„:</strong> 
            <ul>
                <li>é»˜è®¤ä½¿ç”¨7Bæ¨¡å‹ï¼Œå“åº”é€Ÿåº¦å¿«ï¼ˆé€šå¸¸5-15ç§’ï¼‰</li>
                <li>é¦–æ¬¡å¯åŠ¨ä¼šè‡ªåŠ¨ä¸‹è½½7Bæ¨¡å‹ï¼ˆçº¦4GBï¼‰</li>
                <li>7Bæ¨¡å‹å†…å­˜éœ€æ±‚ï¼š8-16GBï¼ŒGPUæ˜¾å­˜ï¼š6-8GB</li>
                <li>ä»å¯ä½¿ç”¨32B/72Bæ¨¡å‹ï¼Œåªéœ€åœ¨APIè°ƒç”¨ä¸­æŒ‡å®šmodelå‚æ•°</li>
            </ul>
        </div>

        <h2>ğŸ”§ Docker ç®¡ç†å‘½ä»¤</h2>
        <pre># å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker compose -f docker-compose-complete.yml up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker compose -f docker-compose-complete.yml ps

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
docker compose -f docker-compose-complete.yml logs -f

# åœæ­¢æ‰€æœ‰æœåŠ¡  
docker compose -f docker-compose-complete.yml down

# é‡å¯æœåŠ¡
docker compose -f docker-compose-complete.yml restart</pre>

        <h2>ğŸ”— è®¿é—®æ–¹å¼</h2>
        <ul>
            <li><strong>nip.ioåŸŸå:</strong> http://10.176.202.207.nip.io</li>
            <li><strong>ç›´æ¥IPè®¿é—®:</strong> http://10.176.202.207</li>
            <li><strong>æœ¬åœ°è®¿é—®:</strong> http://localhost</li>
        </ul>
    </div>
</body>
</html>';
        add_header Content-Type text/html;
    }

    # Ollama API åå‘ä»£ç†
    location /api/ {
        proxy_pass http://ollama_backend;
        
        # åŸºç¡€ä»£ç†å¤´
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # å¤§æ¨¡å‹æ¨ç†è¶…æ—¶é…ç½®
        proxy_connect_timeout 10s;
        proxy_send_timeout 600s;      # 10åˆ†é’Ÿï¼Œé€‚åº”72Bæ¨¡å‹
        proxy_read_timeout 600s;      # 10åˆ†é’Ÿè¯»å–è¶…æ—¶
        
        # æµå¼å“åº”æ”¯æŒ
        proxy_buffering off;
        proxy_cache off;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        
        # æ”¯æŒ Server-Sent Events (SSE)
        proxy_set_header Cache-Control no-cache;
        proxy_set_header X-Accel-Buffering no;
        
        # é”™è¯¯å¤„ç†
        proxy_intercept_errors on;
        error_page 502 503 504 = @ollama_error;
    }

    # Ollama æœåŠ¡é”™è¯¯å¤„ç†
    location @ollama_error {
        return 503 '{"error": "Ollama service temporarily unavailable. Please check if the ollama container is running."}';
        add_header Content-Type application/json;
    }

    # ç®¡ç†æ¥å£ (å¯é€‰)
    location /admin/ {
        return 404 '{"error": "Admin interface not configured"}';
        add_header Content-Type application/json;
    }

    # å®‰å…¨é…ç½®
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Server "Ollama-Proxy/1.0";
}
